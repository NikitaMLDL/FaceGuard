{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_17808\\2648883498.py:6: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  from kerastuner import HyperModel, RandomSearch\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from kerastuner import HyperModel, RandomSearch\n",
    "import os\n",
    "from kerastuner import HyperParameters\n",
    "# Установите URI для отслеживания MLflow\n",
    "mlflow.set_tracking_uri('http://127.0.0.1:5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = os.listdir('augmented')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определите вашу модель CNN\n",
    "def create_model(filters_1=32, filters_2=64, filters_3=128, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters_1, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters_2, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters_3, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(len(classes), activation='softmax'))  # Предполагается 10 классов\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для обучения модели и логирования в MLflow\n",
    "def train_model(filters_1=32, filters_2=64, filters_3=128,\n",
    "                dropout_rate=0.5, learning_rate=0.001,\n",
    "                batch_size=32, epochs=10):\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        # Создание модели с заданными гиперпараметрами\n",
    "        model = create_model(filters_1=filters_1,\n",
    "                             filters_2=filters_2,\n",
    "                             filters_3=filters_3,\n",
    "                             dropout_rate=dropout_rate,\n",
    "                             learning_rate=learning_rate)\n",
    "        \n",
    "        # Подготовка данных из папки augmented\n",
    "        datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2) \n",
    "        \n",
    "        train_generator = datagen.flow_from_directory(\n",
    "            'augmented',\n",
    "            target_size=(100, 100),\n",
    "            batch_size=batch_size,\n",
    "            shuffle = True,\n",
    "            class_mode='categorical',\n",
    "            subset='training'\n",
    "        )\n",
    "        \n",
    "        validation_generator = datagen.flow_from_directory(\n",
    "            'augmented',\n",
    "            target_size=(100, 100),\n",
    "            batch_size=batch_size,\n",
    "            shuffle = True,\n",
    "            class_mode='categorical',\n",
    "            subset='validation'\n",
    "        )\n",
    "        \n",
    "        # Обучение модели с логированием в MLflow и метрик после каждой эпохи\n",
    "        history = model.fit(train_generator,\n",
    "                            validation_data=validation_generator,\n",
    "                            epochs=epochs) \n",
    "        \n",
    "        # Логирование модели в MLflow\n",
    "        mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "        # Логирование гиперпараметров после завершения обучения\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"filters_1\", filters_1)\n",
    "        mlflow.log_param(\"filters_2\", filters_2)\n",
    "        mlflow.log_param(\"filters_3\", filters_3)\n",
    "        mlflow.log_param(\"dropout_rate\", dropout_rate)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "\n",
    "        for epoch in range(len(history.history['val_accuracy'])):\n",
    "            mlflow.log_metric(\"val_accuracy\", history.history['val_accuracy'][epoch], step=epoch)\n",
    "            mlflow.log_metric(\"accuracy\", history.history['accuracy'][epoch], step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", history.history['val_loss'][epoch], step=epoch)  # Сохраняем val_loss\n",
    "            mlflow.log_metric(\"loss\", history.history['loss'][epoch], step=epoch)  # Сохраняем loss\n",
    "\n",
    "        # Создание графика для accuracy\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(history.history['accuracy'], label='accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        # Сохранение графика accuracy как изображения\n",
    "        accuracy_plot_file_path = \"accuracy_plot.png\"\n",
    "        plt.savefig(accuracy_plot_file_path)\n",
    "        \n",
    "        # Закрытие графика\n",
    "        plt.close()\n",
    "\n",
    "        # Логирование изображения accuracy в MLflow\n",
    "        mlflow.log_artifact(accuracy_plot_file_path)\n",
    "\n",
    "        \n",
    "        # Создание графика для loss\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(history.history['loss'], label='loss')\n",
    "        plt.plot(history.history['val_loss'], label='val_loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        # Сохранение графика loss как изображения\n",
    "        loss_plot_file_path = \"loss_plot.png\"\n",
    "        plt.savefig(loss_plot_file_path)\n",
    "        \n",
    "        # Закрытие графика\n",
    "        plt.close()\n",
    "\n",
    "         # Логирование изображения loss в MLflow\n",
    "        mlflow.log_artifact(loss_plot_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "# Списки параметров для перебора\n",
    "filters_1_list = [16, 32]\n",
    "filters_2_list = [32, 64]\n",
    "filters_3_list = [64, 128]\n",
    "dropout_rates = [0.5]\n",
    "learning_rate = [0.001, 0.0001]\n",
    "batch_sizes = [32, 64]\n",
    "epochs_list = [5]\n",
    "\n",
    "# Генерация всех возможных комбинаций параметров\n",
    "param_combinations = itertools.product(filters_1_list,\n",
    "                                        filters_2_list,\n",
    "                                        filters_3_list,\n",
    "                                        dropout_rates,\n",
    "                                        learning_rate,\n",
    "                                        batch_sizes,\n",
    "                                        epochs_list)\n",
    "\n",
    "# Обучение модели для каждой комбинации параметров\n",
    "for params in param_combinations:\n",
    "    filters_1, filters_2, filters_3, dropout_rate, learning_rate, batch_size, epochs = params\n",
    "    \n",
    "    print(f\"Обучение модели с параметрами: \"\n",
    "          f\"filters_1={filters_1}, \"\n",
    "          f\"filters_2={filters_2}, \"\n",
    "          f\"filters_3={filters_3}, \"\n",
    "          f\"dropout_rate={dropout_rate}, \"\n",
    "          f\"learning_rate={learning_rate},\"\n",
    "          f\"batch_size={batch_size}, \"\n",
    "          f\"epochs={epochs}\")\n",
    "    \n",
    "    train_model(filters_1=filters_1,\n",
    "                filters_2=filters_2,\n",
    "                filters_3=filters_3,\n",
    "                dropout_rate=dropout_rate,\n",
    "                learning_rate=learning_rate,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs)\n",
    "\n",
    "print(\"Обучение завершено.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Без ImageGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "def create_model(dropout_rate=0.5, im_shape=(100, 100, 3), learning_rate=0.001):\n",
    "    cnn_model = Sequential([\n",
    "        # Первый сверточный слой\n",
    "        Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=im_shape),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        BatchNormalization(),  # Слой нормализации\n",
    "        Dropout(dropout_rate),          # Слой дропаут\n",
    "\n",
    "        # Второй сверточный слой\n",
    "        # Conv2D(filters=32, kernel_size=(3, 3), activation='relu'),\n",
    "        # MaxPooling2D(pool_size=(2, 2)),\n",
    "        # BatchNormalization(),  # Слой нормализации\n",
    "        # Dropout(dropout_rate),          # Слой дропаут\n",
    "\n",
    "        Flatten(),             # Преобразование в одномерный вектор\n",
    "\n",
    "        # Полносвязный слой\n",
    "        Dense(1024, activation='relu'),\n",
    "\n",
    "        # Выходной слой для классификации на 43 класса\n",
    "        Dense(len(classes), activation='softmax')  \n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    cnn_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "def create_model(dropout_rate=0.5, im_shape=(100, 100, 3), learning_rate=0.001):\n",
    "    cnn_model = Sequential([\n",
    "        Conv2D(filters=36, kernel_size=7, activation='relu', input_shape=im_shape),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Conv2D(filters=54, kernel_size=5, activation='relu'),\n",
    "        MaxPooling2D(pool_size=2),\n",
    "        Flatten(),\n",
    "        Dense(2024, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1024, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(classes), activation='softmax')  # Предполагается 20 классов\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    cnn_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "# Определите вашу модель CNN\n",
    "def create_model(filters_1=32, filters_2=64, filters_3=128, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters_1, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Conv2D(filters_2, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters_3, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(len(classes), activation='softmax'))  # Предполагается 10 классов\n",
    "    \n",
    "    optimazer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimazer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def load_image(file_path, target_size=(100, 100)):\n",
    "    \"\"\"\n",
    "    Загружает изображение из указанного пути, изменяет его размер и нормализует пиксели.\n",
    "\n",
    "    :param file_path: Путь к файлу изображения.\n",
    "    :param target_size: Размер, до которого нужно изменить изображение (ширина, высота).\n",
    "    :return: Нормализованное изображение в виде массива NumPy.\n",
    "    \"\"\"\n",
    "    # Открываем изображение\n",
    "    image = Image.open(file_path)\n",
    "\n",
    "    # Изменяем размер изображения\n",
    "    image = image.resize(target_size)\n",
    "\n",
    "    # Преобразуем изображение в массив NumPy\n",
    "    image_array = np.array(image)\n",
    "\n",
    "    # Нормализация пикселей (если необходимо)\n",
    "    # Приводим значения пикселей к диапазону [0, 1]\n",
    "    image_array = image_array / 255.0\n",
    "\n",
    "    return image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "def train_model(X_train, X_test, y_train, y_test,\n",
    "                dropout_rate=0.5, learning_rate=0.001,\n",
    "                batch_size=32, epochs=10):\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        # Создание модели с заданными гиперпараметрами\n",
    "        model = create_model(dropout_rate=dropout_rate,\n",
    "                             learning_rate=learning_rate)\n",
    "        early_stopping = EarlyStopping(monitor='val_loss',  # Можно использовать 'val_accuracy' для мониторинга точности\n",
    "                               patience=2,         # Количество эпох без улучшения перед остановкой\n",
    "                               restore_best_weights=True)  # Восстановить лучшие веса\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_loss',  # Метрика для мониторинга\n",
    "                               factor=0.5,          # На сколько уменьшать learning rate\n",
    "                               patience=2,         # Количество эпох без улучшения перед уменьшением\n",
    "                               min_lr=1e-6)        # Минимально допустимый learning rate\n",
    "        \n",
    "        # Обучение модели с логированием в MLflow и метрик после каждой эпохи\n",
    "        history = model.fit(X_train,\n",
    "                            y_train,\n",
    "                            validation_data=(X_test, y_test),\n",
    "                            epochs=epochs,\n",
    "                            batch_size=batch_size,\n",
    "                            callbacks=[early_stopping])\n",
    "        \n",
    "        # Логирование модели в MLflow\n",
    "        mlflow.keras.log_model(model, \"model\")\n",
    "\n",
    "        # Логирование гиперпараметров после завершения обучения\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"dropout_rate\", dropout_rate)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "\n",
    "        for epoch in range(len(history.history['val_accuracy'])):\n",
    "            mlflow.log_metric(\"val_accuracy\", history.history['val_accuracy'][epoch], step=epoch)\n",
    "            mlflow.log_metric(\"accuracy\", history.history['accuracy'][epoch], step=epoch)\n",
    "            mlflow.log_metric(\"val_loss\", history.history['val_loss'][epoch], step=epoch)  \n",
    "            mlflow.log_metric(\"loss\", history.history['loss'][epoch], step=epoch)  \n",
    "\n",
    "        # Создание графика для accuracy\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(history.history['accuracy'], label='accuracy')\n",
    "        plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        # Сохранение графика accuracy как изображения\n",
    "        accuracy_plot_file_path = \"accuracy_plot.png\"\n",
    "        plt.savefig(accuracy_plot_file_path)\n",
    "        \n",
    "        # Закрытие графика\n",
    "        plt.close()\n",
    "\n",
    "        # Логирование изображения accuracy в MLflow\n",
    "        mlflow.log_artifact(accuracy_plot_file_path)\n",
    "\n",
    "    \n",
    "        # Создание графика для loss\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.plot(history.history['loss'], label='loss')\n",
    "        plt.plot(history.history['val_loss'], label='val_loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='upper left')\n",
    "\n",
    "        # Сохранение графика loss как изображения\n",
    "        loss_plot_file_path = \"loss_plot.png\"\n",
    "        plt.savefig(loss_plot_file_path)\n",
    "\n",
    "        # Закрытие графика \n",
    "        plt.close()\n",
    "\n",
    "        # Логирование изображения loss в MLflow \n",
    "        mlflow.log_artifact(loss_plot_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "data_dir = 'augmented'\n",
    "for person_folder in os.listdir(data_dir):\n",
    "    person_path = os.path.join(data_dir, person_folder)\n",
    "    if os.path.isdir(person_path):  # Проверяем, что это папка\n",
    "        for file_name in os.listdir(person_path):\n",
    "            file_path = os.path.join(person_path, file_name)\n",
    "            if file_name.endswith('.jpg') or file_name.endswith('.png'):  # Замените на нужные форматы\n",
    "                # Здесь вы можете загрузить изображение или данные\n",
    "                image = load_image(file_path)  # Замените на вашу функцию загрузки изображения\n",
    "                X.append(image)\n",
    "                y.append(person_folder)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12400"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "del y_one_hot, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер X: (12400, 100, 100, 3)\n",
      "Размер y (one-hot): (12400, 31)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)  # sparse=False для получения массива NumPy вместо разреженной матрицы\n",
    "y_one_hot = encoder.fit_transform(y.reshape(-1, 1))  # Преобразуем y в двумерный массив\n",
    "\n",
    "print(\"Размер X:\", X.shape)\n",
    "print(\"Размер y (one-hot):\", y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки X: (9920, 100, 100, 3)\n",
      "Размер тестовой выборки X: (2480, 100, 100, 3)\n",
      "Размер обучающей выборки y: (9920, 31)\n",
      "Размер тестовой выборки y: (2480, 31)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Размер обучающей выборки X:\", X_train.shape)\n",
    "print(\"Размер тестовой выборки X:\", X_test.shape)\n",
    "print(\"Размер обучающей выборки y:\", y_train.shape)\n",
    "print(\"Размер тестовой выборки y:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучение модели с параметрами: dropout_rate=0.4, learning_rate=0.0001,batch_size=32, epochs=10\n",
      "Epoch 1/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 157ms/step - accuracy: 0.2437 - loss: 3.0382 - val_accuracy: 0.1565 - val_loss: 2.9761\n",
      "Epoch 2/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 153ms/step - accuracy: 0.6723 - loss: 1.1088 - val_accuracy: 0.6944 - val_loss: 1.0675\n",
      "Epoch 3/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 153ms/step - accuracy: 0.8547 - loss: 0.4979 - val_accuracy: 0.8153 - val_loss: 0.6763\n",
      "Epoch 4/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 153ms/step - accuracy: 0.9374 - loss: 0.2390 - val_accuracy: 0.8452 - val_loss: 0.5475\n",
      "Epoch 5/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 154ms/step - accuracy: 0.9715 - loss: 0.1285 - val_accuracy: 0.8637 - val_loss: 0.5051\n",
      "Epoch 6/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 155ms/step - accuracy: 0.9799 - loss: 0.0908 - val_accuracy: 0.8730 - val_loss: 0.4667\n",
      "Epoch 7/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 155ms/step - accuracy: 0.9898 - loss: 0.0590 - val_accuracy: 0.8685 - val_loss: 0.4700\n",
      "Epoch 8/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 156ms/step - accuracy: 0.9938 - loss: 0.0421 - val_accuracy: 0.8706 - val_loss: 0.4497\n",
      "Epoch 9/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 158ms/step - accuracy: 0.9927 - loss: 0.0356 - val_accuracy: 0.8661 - val_loss: 0.4737\n",
      "Epoch 10/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 153ms/step - accuracy: 0.9959 - loss: 0.0272 - val_accuracy: 0.8802 - val_loss: 0.4456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/01 21:47:33 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/04/01 21:47:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run fearless-snail-50 at: http://127.0.0.1:5000/#/experiments/0/runs/b2938ffa77194b1492095df54188f399\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n",
      "Обучение модели с параметрами: dropout_rate=0.4, learning_rate=0.0001,batch_size=64, epochs=10\n",
      "Epoch 1/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 271ms/step - accuracy: 0.2254 - loss: 3.1316 - val_accuracy: 0.0597 - val_loss: 3.5818\n",
      "Epoch 2/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 269ms/step - accuracy: 0.6243 - loss: 1.3057 - val_accuracy: 0.1089 - val_loss: 3.5060\n",
      "Epoch 3/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 273ms/step - accuracy: 0.7864 - loss: 0.7297 - val_accuracy: 0.5040 - val_loss: 1.7085\n",
      "Epoch 4/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 270ms/step - accuracy: 0.8886 - loss: 0.4069 - val_accuracy: 0.7476 - val_loss: 0.8964\n",
      "Epoch 5/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 269ms/step - accuracy: 0.9462 - loss: 0.2289 - val_accuracy: 0.8133 - val_loss: 0.6610\n",
      "Epoch 6/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 270ms/step - accuracy: 0.9672 - loss: 0.1502 - val_accuracy: 0.8435 - val_loss: 0.5884\n",
      "Epoch 7/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 273ms/step - accuracy: 0.9826 - loss: 0.0961 - val_accuracy: 0.8540 - val_loss: 0.5389\n",
      "Epoch 8/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 283ms/step - accuracy: 0.9856 - loss: 0.0782 - val_accuracy: 0.8573 - val_loss: 0.5370\n",
      "Epoch 9/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 282ms/step - accuracy: 0.9904 - loss: 0.0564 - val_accuracy: 0.8613 - val_loss: 0.5130\n",
      "Epoch 10/10\n",
      "\u001b[1m155/155\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 269ms/step - accuracy: 0.9950 - loss: 0.0430 - val_accuracy: 0.8621 - val_loss: 0.5111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/01 21:55:34 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n",
      "2025/04/01 21:55:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run rare-boar-299 at: http://127.0.0.1:5000/#/experiments/0/runs/489b382abf054da89ee7f019baeae21c\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n",
      "Обучение модели с параметрами: dropout_rate=0.3, learning_rate=0.0001,batch_size=32, epochs=10\n",
      "Epoch 1/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 153ms/step - accuracy: 0.2818 - loss: 2.7842 - val_accuracy: 0.1512 - val_loss: 3.2244\n",
      "Epoch 2/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 166ms/step - accuracy: 0.7527 - loss: 0.8598 - val_accuracy: 0.6810 - val_loss: 1.0734\n",
      "Epoch 3/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 163ms/step - accuracy: 0.9058 - loss: 0.3472 - val_accuracy: 0.8262 - val_loss: 0.6248\n",
      "Epoch 4/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 163ms/step - accuracy: 0.9673 - loss: 0.1551 - val_accuracy: 0.8460 - val_loss: 0.5337\n",
      "Epoch 5/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 154ms/step - accuracy: 0.9867 - loss: 0.0749 - val_accuracy: 0.8565 - val_loss: 0.4974\n",
      "Epoch 6/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 154ms/step - accuracy: 0.9893 - loss: 0.0571 - val_accuracy: 0.8730 - val_loss: 0.4693\n",
      "Epoch 7/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 154ms/step - accuracy: 0.9924 - loss: 0.0391 - val_accuracy: 0.8669 - val_loss: 0.4764\n",
      "Epoch 8/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 157ms/step - accuracy: 0.9974 - loss: 0.0255 - val_accuracy: 0.8798 - val_loss: 0.4349\n",
      "Epoch 9/10\n",
      "\u001b[1m310/310\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 199ms/step - accuracy: 0.9971 - loss: 0.0188 - val_accuracy: 0.8690 - val_loss: 0.4820\n",
      "Epoch 10/10\n",
      "\u001b[1m 31/310\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 155ms/step - accuracy: 0.9982 - loss: 0.0200🏃 View run suave-sheep-358 at: http://127.0.0.1:5000/#/experiments/0/runs/6fb4ee4aaa464b3799b6a8523c96a1a7\n",
      "🧪 View experiment at: http://127.0.0.1:5000/#/experiments/0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     16\u001b[39m     dropout_rate, learning_rate, batch_size, epochs = params\n\u001b[32m     18\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mОбучение модели с параметрами: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     19\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdropout_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     20\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mlearning_rate=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     21\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbatch_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mepochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                \u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mОбучение завершено.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(X_train, X_test, y_train, y_test, dropout_rate, learning_rate, batch_size, epochs)\u001b[39m\n\u001b[32m     11\u001b[39m early_stopping = EarlyStopping(monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# Можно использовать 'val_accuracy' для мониторинга точности\u001b[39;00m\n\u001b[32m     12\u001b[39m                        patience=\u001b[32m5\u001b[39m,         \u001b[38;5;66;03m# Количество эпох без улучшения перед остановкой\u001b[39;00m\n\u001b[32m     13\u001b[39m                        restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Восстановить лучшие веса\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Обучение модели с логированием в MLflow и метрик после каждой эпохи\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Логирование модели в MLflow\u001b[39;00m\n\u001b[32m     23\u001b[39m mlflow.keras.log_model(model, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\User\\anaconda3\\envs\\cv_project\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "dropout_rates = [0.4, 0.3]\n",
    "learning_rate = [0.0001]\n",
    "batch_sizes = [32, 64]\n",
    "epochs_list = [10]\n",
    "\n",
    "# Генерация всех возможных комбинаций параметров\n",
    "param_combinations = itertools.product(dropout_rates,\n",
    "                                        learning_rate,\n",
    "                                        batch_sizes,\n",
    "                                        epochs_list)\n",
    "\n",
    "# Обучение модели для каждой комбинации параметров\n",
    "for params in param_combinations:\n",
    "    dropout_rate, learning_rate, batch_size, epochs = params\n",
    "    \n",
    "    print(f\"Обучение модели с параметрами: \"\n",
    "          f\"dropout_rate={dropout_rate}, \"\n",
    "          f\"learning_rate={learning_rate},\"\n",
    "          f\"batch_size={batch_size}, \"\n",
    "          f\"epochs={epochs}\")\n",
    "    \n",
    "    train_model(X_train, X_test, y_train, y_test,\n",
    "                dropout_rate=dropout_rate,\n",
    "                learning_rate=learning_rate,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs)\n",
    "\n",
    "print(\"Обучение завершено.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
